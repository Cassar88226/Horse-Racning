{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608696, 44)\n"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "dataframe = pd.read_csv(\"dataset.csv\")\n",
    "print(dataframe.shape)\n",
    "# dataframe = dataframe.drop_duplicates()\n",
    "# pick up features from dataset\n",
    "feature_df = dataframe[['day', 'raceno', 'venuename', 'racedistance', 'horseid', 'row', 'trainer', 'driver', 'handicap', 'age', 'place']].copy()\n",
    "\n",
    "\n",
    "\n",
    "# Label Encoding of feature and store them\n",
    "\n",
    "# venue encoding\n",
    "venue_le = LabelEncoder()\n",
    "feature_df['venuename'] = venue_le.fit_transform(feature_df['venuename'])\n",
    "\n",
    "\n",
    "with open(\"VenueName_Encoder.pkl\", 'wb') as venue_file:\n",
    "    pickle.dump(venue_le, venue_file)\n",
    "    venue_file.close()\n",
    "\n",
    "# row encoding\n",
    "row_le = LabelEncoder()\n",
    "feature_df['row'] = row_le.fit_transform(feature_df['row'])\n",
    "\n",
    "\n",
    "with open(\"Row_Encoder.pkl\", 'wb') as row_file:\n",
    "    pickle.dump(row_le, row_file)\n",
    "    row_file.close()\n",
    "\n",
    "# trainer encoding\n",
    "trainer_le = LabelEncoder()\n",
    "feature_df['trainer'] = trainer_le.fit_transform(feature_df['trainer'])\n",
    "\n",
    "\n",
    "with open(\"Trainer_Encoder.pkl\", 'wb') as trainer_file:\n",
    "    pickle.dump(trainer_le, trainer_file)\n",
    "    trainer_file.close()\n",
    "\n",
    "# trainer encoding\n",
    "driver_le = LabelEncoder()\n",
    "feature_df['driver'] = driver_le.fit_transform(feature_df['driver'])\n",
    "\n",
    "\n",
    "with open(\"Driver_Encoder.pkl\", 'wb') as driver_file:\n",
    "    pickle.dump(driver_le, driver_file)\n",
    "    driver_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(603535, 11)\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000212900D8B50>\n",
      "['venuename', 'racedistance', 'horseid1', 'row1', 'trainer1', 'driver1', 'handicap1', 'age1', 'horseid2', 'row2', 'trainer2', 'driver2', 'handicap2', 'age2', 'horseid3', 'row3', 'trainer3', 'driver3', 'handicap3', 'age3', 'horseid4', 'row4', 'trainer4', 'driver4', 'handicap4', 'age4', 'horseid5', 'row5', 'trainer5', 'driver5', 'handicap5', 'age5', 'horseid6', 'row6', 'trainer6', 'driver6', 'handicap6', 'age6', 'horseid7', 'row7', 'trainer7', 'driver7', 'handicap7', 'age7', 'horseid8', 'row8', 'trainer8', 'driver8', 'handicap8', 'age8', 'horseid9', 'row9', 'trainer9', 'driver9', 'handicap9', 'age9', 'horseid10', 'row10', 'trainer10', 'driver10', 'handicap10', 'age10', 'horseid11', 'row11', 'trainer11', 'driver11', 'handicap11', 'age11', 'horseid12', 'row12', 'trainer12', 'driver12', 'handicap12', 'age12', 'horseid13', 'row13', 'trainer13', 'driver13', 'handicap13', 'age13', 'horseid14', 'row14', 'trainer14', 'driver14', 'handicap14', 'age14', 'horseid15', 'row15', 'trainer15', 'driver15', 'handicap15', 'age15', 'horseid16', 'row16', 'trainer16', 'driver16', 'handicap16', 'age16', 'horseid17', 'row17', 'trainer17', 'driver17', 'handicap17', 'age17', 'horseid18', 'row18', 'trainer18', 'driver18', 'handicap18', 'age18', 'horseid19', 'row19', 'trainer19', 'driver19', 'handicap19', 'age19', 'place1', 'place2', 'place3', 'place4', 'place5', 'place6', 'place7', 'place8', 'place9', 'place10', 'place11', 'place12', 'place13', 'place14', 'place15', 'place16', 'place17', 'place18', 'place19']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-559ebc01c2f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'place'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mresult_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index_names = feature_df[ feature_df['place'] == 0 ].index\n",
    "feature_df.drop(index_names,inplace = True)\n",
    "feature_df = feature_df.drop_duplicates()\n",
    "\n",
    "print(feature_df.shape)\n",
    "\n",
    "\n",
    "# Create Pivot table\n",
    "\n",
    "group_df = feature_df.groupby(['day', 'raceno', 'venuename', 'racedistance'])\n",
    "print(group_df)\n",
    "columns = ['venuename', 'racedistance']\n",
    "common_columns = ['horseid', 'row', 'trainer', 'driver', 'handicap', 'age']\n",
    "max_number = 19\n",
    "for i in range(1, max_number + 1):\n",
    "    ith_columns = []\n",
    "    for column in common_columns:\n",
    "        ith_columns.append(column + str(i))\n",
    "    columns += ith_columns\n",
    "place_columns = []\n",
    "for i in range(1, max_number + 1):\n",
    "    place_columns.append('place' + str(i))\n",
    "\n",
    "columns += place_columns\n",
    "\n",
    "\n",
    "result_df = pd.DataFrame(columns = columns)\n",
    "\n",
    "print(columns)\n",
    "\n",
    "for group_name, df in group_df:\n",
    "    # print(group_df)\n",
    "    day, raceno, venuename, racedistance = group_name\n",
    "    item = OrderedDict()\n",
    "    item['venuename'] = venuename\n",
    "    item['racedistance'] = racedistance\n",
    "    index = 1\n",
    "    for i, row in df.iterrows():\n",
    "        item['horseid' + str(index)] = row['horseid']\n",
    "        item['row' + str(index)] = row['row']\n",
    "        item['trainer' + str(index)] = row['trainer']\n",
    "        item['driver' + str(index)] = row['driver']\n",
    "        item['horseid' + str(index)] = row['horseid']\n",
    "        item['handicap' + str(index)] = row['handicap']\n",
    "        item['age' + str(index)] = row['age']\n",
    "        item['place' + str(index)] = row['place']\n",
    "        index += 1\n",
    "    if index >= max_number:\n",
    "        continue\n",
    "    for index1 in range(index, max_number+1):\n",
    "        item['horseid' + str(index1)] = 0\n",
    "        item['row' + str(index1)] = 0\n",
    "        item['trainer' + str(index1)] = 0\n",
    "        item['driver' + str(index1)] = 0\n",
    "        item['horseid' + str(index1)] = 0\n",
    "        item['handicap' + str(index1)] = 0\n",
    "        item['age' + str(index1)] = 0\n",
    "        item['place' + str(index1)] = 0\n",
    "    result_df = result_df.append(item, ignore_index = True)\n",
    "\n",
    "result_df = result_df.fillna(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('feature selection.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "racing_venv",
   "language": "python",
   "name": "racing_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
